cluster.assignment.kmeans <- mod$cluster
table(cluster.assignment.kmeans)
#kmeans_data <- cbind(data,cluster.assignment.kmeans)
#kmeans_data %>% group_by(cluster.assignment.kmeans, Industry) %>% summarise(count=n())
t(as.data.frame.matrix(table(cluster.assignment.kmeans), clustered_data$Industry))
### k-means
## k-means with k=8
set.seed(2407)
# Running the k means algorithm
mod <- kmeans(returns, iter.max=100, 8)
cluster.assignment.kmeans <- mod$cluster
table(cluster.assignment.kmeans)
#kmeans_data <- cbind(data,cluster.assignment.kmeans)
#kmeans_data %>% group_by(cluster.assignment.kmeans, Industry) %>% summarise(count=n())
t(as.data.frame.matrix(table(cluster.assignment.kmeans, clustered_data$Industry)))
mod$centers[,"avg200810"]
mod$centers[,"avg200903"]
### k-means
## k-means with k=8
set.seed(2407)
# Running the k means algorithm
mod <- kmeans(returns, iter.max=100, 8)
cluster.assignment.kmeans <- mod$cluster
table(cluster.assignment.kmeans)
kmeans_data <- cbind(data,cluster.assignment.kmeans)
#kmeans_data %>% group_by(cluster.assignment.kmeans, Industry) %>% summarise(count=n())
t(as.data.frame.matrix(table(cluster.assignment.kmeans, kmeans_data$Industry)))
mod$centers[,"avg200810"]
mod$centers[,"avg200903"]
### (e)
sum(ebay.valid$Competitive.==1)/nrow(ebay.valid)
library(gdata)
ebay.df = read.xls("eBayAuctions.xls")
table(ebay.df$Competitive)
ebay.df$competitive.factor <- as.factor(ebay.df$Competitive.)
ebay.df$Category <- as.factor(ebay.df$Category)
ebay.df$currency <- as.factor(ebay.df$currency)
ebay.df$endDay <- as.factor(ebay.df$endDay)
ebay.df$Duration <- as.factor(ebay.df$Duration)
split = createDataPartition(ebay.df$competitive.factor, p = 0.60, list = FALSE)
ebay.train <- ebay.df[split,]
ebay.valid <- ebay.df[-split,]
cutoff = 1066/(1066+906)
### (e)
sum(ebay.valid$Competitive.==1)/nrow(ebay.valid)
library(gdata)
ebay.df = read.xls("eBayAuctions.xls")
table(ebay.df$Competitive)
ebay.df$competitive.factor <- as.factor(ebay.df$Competitive.)
ebay.df$Category <- as.factor(ebay.df$Category)
ebay.df$currency <- as.factor(ebay.df$currency)
ebay.df$endDay <- as.factor(ebay.df$endDay)
ebay.df$Duration <- as.factor(ebay.df$Duration)
split = createDataPartition(ebay.df$competitive.factor, p = 0.60, list = FALSE)
ebay.train <- ebay.df[split,]
ebay.valid <- ebay.df[-split,]
cutoff = sum(ebay.df$Competitive.==1)/nrow(ebay.df)
library(gdata)
ebay.df = read.xls("eBayAuctions.xls")
table(ebay.df$Competitive)
ebay.df$competitive.factor <- as.factor(ebay.df$Competitive.)
ebay.df$Category <- as.factor(ebay.df$Category)
ebay.df$currency <- as.factor(ebay.df$currency)
ebay.df$endDay <- as.factor(ebay.df$endDay)
ebay.df$Duration <- as.factor(ebay.df$Duration)
split = createDataPartition(ebay.df$competitive.factor, p = 0.60, list = FALSE)
ebay.train <- ebay.df[split,]
ebay.valid <- ebay.df[-split,]
cutoff = sum(ebay.df$Competitive.==1)/nrow(ebay.df)
## adaboost
set.seed(111)
adaboost_a <- boosting(competitive.factor~. -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_a, cex.names=0.7)
# training
ada_pred_a_train <- predict(adaboost_a, newdata = ebay.train, type = "class")
ada_a_train_con <- confusionMatrix(factor(ada_pred_a_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_a_train_con
# validation
ada_pred_a_valid <- predict(adaboost_a, newdata = ebay.valid, type = "class")
ada_a_valid_con <- confusionMatrix(factor(ada_pred_a_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_a_valid_con
## adaboost
set.seed(15071)
adaboost_a <- boosting(competitive.factor~. -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_a, cex.names=0.7)
# training
ada_pred_a_train <- predict(adaboost_a, newdata = ebay.train, type = "class")
ada_a_train_con <- confusionMatrix(factor(ada_pred_a_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_a_train_con
# validation
ada_pred_a_valid <- predict(adaboost_a, newdata = ebay.valid, type = "class")
ada_a_valid_con <- confusionMatrix(factor(ada_pred_a_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_a_valid_con
## xgboost
set.seed(111)
xgb_a <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.)))), model = xgb_a)
# training
xgb_a_train_con <- confusionMatrix(factor(1*(predict(xgb_a, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_a_train_con
# validation
xgb_a_valid_con <- confusionMatrix(factor(1*(predict(xgb_a, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_a_valid_con
## bagging
set.seed(111)
bag_a <- bagging(competitive.factor~. -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_a, cex.names=0.7)
# training
bag_pred_a_train <- predict(bag_a, newdata = ebay.train, type = "class")
bag_a_train_con <- confusionMatrix(factor(bag_pred_a_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_a_train_con
# validation
bag_pred_a_valid <- predict(bag_a, newdata = ebay.valid, type = "class")
bag_a_valid_con <- confusionMatrix(factor(bag_pred_a_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
bag_a_valid_con
## xgboost
set.seed(15071)
xgb_a <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.)))), model = xgb_a)
# training
xgb_a_train_con <- confusionMatrix(factor(1*(predict(xgb_a, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_a_train_con
# validation
xgb_a_valid_con <- confusionMatrix(factor(1*(predict(xgb_a, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_a_valid_con
## bagging
set.seed(15071)
bag_a <- bagging(competitive.factor~. -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_a, cex.names=0.7)
# training
bag_pred_a_train <- predict(bag_a, newdata = ebay.train, type = "class")
bag_a_train_con <- confusionMatrix(factor(bag_pred_a_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_a_train_con
# validation
bag_pred_a_valid <- predict(bag_a, newdata = ebay.valid, type = "class")
bag_a_valid_con <- confusionMatrix(factor(bag_pred_a_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
bag_a_valid_con
## random forest
set.seed(15071)
rf_a <- randomForest(Competitive.~. -competitive.factor, data=ebay.train, method = "class")
# variable importance
varImp(rf_a, conditional=TRUE)
# training
rf_pred_a_train <- predict(rf_a, newdata = ebay.train, type = "class")
rf_a_train_con <- confusionMatrix(factor(rf_pred_a_train>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_a_train_con
# validation
rf_pred_a_valid <- predict(rf_a, newdata = ebay.valid, type = "class")
rf_a_valid_con <- confusionMatrix(factor(rf_pred_a_valid>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_a_valid_con
## adaboost
adaboost_b <- boosting(competitive.factor~. -ClosePrice -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_b, cex.names=0.7)
# training
ada_pred_b_train <- predict(adaboost_b, newdata = ebay.train, type = "class")
ada_b_train_con <- confusionMatrix(factor(ada_pred_b_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_b_train_con
# validation
ada_pred_b_valid <- predict(adaboost_b, newdata = ebay.valid, type = "class")
ada_b_valid_con <- confusionMatrix(factor(ada_pred_b_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_b_valid_con
## adaboost
set.seed(15071)
adaboost_b <- boosting(competitive.factor~. -ClosePrice -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_b, cex.names=0.7)
# training
ada_pred_b_train <- predict(adaboost_b, newdata = ebay.train, type = "class")
ada_b_train_con <- confusionMatrix(factor(ada_pred_b_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_b_train_con
# validation
ada_pred_b_valid <- predict(adaboost_b, newdata = ebay.valid, type = "class")
ada_b_valid_con <- confusionMatrix(factor(ada_pred_b_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_b_valid_con
## xgboost
set.seed(15071)
xgb_b <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.)))), model = xgb_b)
# training
xgb_b_train_con <- confusionMatrix(factor(1*(predict(xgb_b, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_b_train_con
# validation
xgb_b_valid_con <- confusionMatrix(factor(1*(predict(xgb_b, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive.))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_b_valid_con
## random forest
set.seed(15071)
rf_b <- randomForest(competitive.factor~. -ClosePrice -Competitive., data=ebay.train, method = "class")
# variable importance
varImp(rf_b, conditional=TRUE)
# training
rf_pred_b_train <- predict(rf_b, newdata = ebay.train, type = "prob")
rf_pred_b_train
rf_b_train_con <- confusionMatrix(factor(rf_pred_b_train[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_b_train_con
# validation
rf_pred_b_valid <- predict(rf_b, newdata = ebay.valid, type = "prob")
rf_b_valid_con <- confusionMatrix(factor(rf_pred_b_valid[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_b_valid_con
## random forest
set.seed(15071)
rf_b <- randomForest(competitive.factor~. -ClosePrice -Competitive., data=ebay.train, method = "class")
# variable importance
varImp(rf_b, conditional=TRUE)
# training
rf_pred_b_train <- predict(rf_b, newdata = ebay.train, type = "prob")
rf_b_train_con <- confusionMatrix(factor(rf_pred_b_train[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_b_train_con
# validation
rf_pred_b_valid <- predict(rf_b, newdata = ebay.valid, type = "prob")
rf_b_valid_con <- confusionMatrix(factor(rf_pred_b_valid[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_b_valid_con
## xgboost
set.seed(15071)
xgb_b <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., ClosePrice))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., ClosePrice)))), model = xgb_b)
# training
xgb_b_train_con <- confusionMatrix(factor(1*(predict(xgb_b, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_b_train_con
# validation
xgb_b_valid_con <- confusionMatrix(factor(1*(predict(xgb_b, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive., ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_b_valid_con
## bagging
bag_b <- bagging(competitive.factor~. -ClosePrice -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_b, cex.names=0.7)
# training
bag_pred_b_train <- predict(bag_b, newdata = ebay.train, type = "class")
bag_a_train_con <- confusionMatrix(factor(bag_pred_b_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_b_train_con
## bagging
bag_b <- bagging(competitive.factor~. -ClosePrice -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_b, cex.names=0.7)
# training
bag_pred_b_train <- predict(bag_b, newdata = ebay.train, type = "class")
bag_b_train_con <- confusionMatrix(factor(bag_pred_b_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_b_train_con
# validation
bag_pred_b_valid <- predict(bag_b, newdata = ebay.valid, type = "class")
bag_b_valid_con <- confusionMatrix(factor(bag_pred_b_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
bag_b_valid_con
## random forest
set.seed(15071)
rf_b <- randomForest(competitive.factor~. -ClosePrice -Competitive., data=ebay.train, method = "class")
# variable importance
varImp(rf_b, conditional=TRUE)
# training
rf_pred_b_train <- predict(rf_b, newdata = ebay.train, type = "prob")
rf_b_train_con <- confusionMatrix(factor(rf_pred_b_train[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_b_train_con
# validation
rf_pred_b_valid <- predict(rf_b, newdata = ebay.valid, type = "prob")
rf_b_valid_con <- confusionMatrix(factor(rf_pred_b_valid[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_b_valid_con
## adaboost
set.seed(15071)
adaboost_c <- boosting(competitive.factor~. -OpenPrice -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_c, cex.names=0.7)
# training
ada_pred_c_train <- predict(adaboost_c, newdata = ebay.train, type = "class")
ada_c_train_con <- confusionMatrix(factor(ada_pred_c_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_c_train_con
# validation
ada_pred_c_valid <- predict(adaboost_c, newdata = ebay.valid, type = "class")
ada_c_valid_con <- confusionMatrix(factor(ada_pred_c_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_c_valid_con
## xgboost
set.seed(15071)
xgb_c <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice)))), model = xgb_c)
# training
xgb_c_train_con <- confusionMatrix(factor(1*(predict(xgb_c, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_c_train_con
# validation
xgb_c_valid_con <- confusionMatrix(factor(1*(predict(xgb_c, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive., OpenPrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_c_valid_con
## bagging
set.seed(15071)
bag_c <- bagging(competitive.factor~. -OpenPrice -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_c, cex.names=0.7)
# training
bag_pred_c_train <- predict(bag_c, newdata = ebay.train, type = "class")
bag_c_train_con <- confusionMatrix(factor(bag_pred_c_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_c_train_con
# validation
bag_pred_c_valid <- predict(bag_c, newdata = ebay.valid, type = "class")
bag_c_valid_con <- confusionMatrix(factor(bag_pred_c_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
bag_c_valid_con
## random forest
set.seed(15071)
rf_c <- randomForest(competitive.factor~. -OpenPrice -Competitive., data=ebay.train, method = "class")
# variable importance
varImp(rf_c, conditional=TRUE)
# training
rf_pred_c_train <- predict(rf_c, newdata = ebay.train, type = "prob")
rf_c_train_con <- confusionMatrix(factor(rf_pred_c_train[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_c_train_con
# validation
rf_pred_c_valid <- predict(rf_c, newdata = ebay.valid, type = "prob")
rf_c_valid_con <- confusionMatrix(factor(rf_pred_c_valid[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_c_valid_con
## adaboost
set.seed(15071)
adaboost_d <- boosting(competitive.factor~. -ClosePrice -OpenPrice -Competitive., data = ebay.train)
# variable importance
importanceplot(adaboost_d, cex.names=0.7)
# training
ada_pred_d_train <- predict(adaboost_d, newdata = ebay.train, type = "class")
ada_d_train_con <- confusionMatrix(factor(ada_pred_d_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
ada_d_train_con
# validation
ada_pred_d_valid <- predict(adaboost_d, newdata = ebay.valid, type = "class")
ada_d_valid_con <- confusionMatrix(factor(ada_pred_d_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
ada_d_valid_con
## xgboost
xgb_d <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice)))), model = xgb_d)
# training
xgb_d_train_con <- confusionMatrix(factor(1*(predict(xgb_d, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_d_train_con
# validation
xgb_d_valid_con <- confusionMatrix(factor(1*(predict(xgb_d, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_d_valid_con
## xgboost
set.seed(15071)
xgb_d <- xgboost(data = model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))), label = ebay.train$Competitive., max.depth = 20, eta = 1, nthread = 2, nrounds = 50, objective = "binary:logistic", verbose = 0)
# variable importance
xgb.importance(colnames(model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice)))), model = xgb_d)
# training
xgb_d_train_con <- confusionMatrix(factor(1*(predict(xgb_d, model.matrix(~ .-1, subset(ebay.train, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.train$competitive.factor)$overall['Accuracy']
xgb_d_train_con
# validation
xgb_d_valid_con <- confusionMatrix(factor(1*(predict(xgb_d, model.matrix(~ .-1, subset(ebay.valid, select=-c(competitive.factor, Competitive., OpenPrice, ClosePrice))))>sum(ebay.df$Competitive.==1)/nrow(ebay.df))), ebay.valid$competitive.factor)$overall['Accuracy']
xgb_d_valid_con
## bagging
set.seed(15071)
bag_d <- bagging(competitive.factor~. -ClosePrice -OpenPrice -Competitive., data = ebay.train)
# variable importance
importanceplot(bag_d, cex.names=0.7)
# training
bag_pred_d_train <- predict(bag_d, newdata = ebay.train, type = "class")
bag_d_train_con <- confusionMatrix(factor(bag_pred_d_train$prob[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
bag_d_train_con
# validation
bag_pred_d_valid <- predict(bag_d, newdata = ebay.valid, type = "class")
bag_d_valid_con <- confusionMatrix(factor(bag_pred_d_valid$prob[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
bag_d_valid_con
## random forest
set.seed(15071)
rf_d <- randomForest(competitive.factor~. -Competitive., data=ebay.train, method = "class")
# variable importance
varImp(rf_d, conditional=TRUE)
# training
rf_pred_d_train <- predict(rf_d, newdata = ebay.train, type = "prob")
rf_d_train_con <- confusionMatrix(factor(rf_pred_d_train[,2]>cutoff, labels = c(0,1)), ebay.train$competitive.factor)$overall['Accuracy']
rf_d_train_con
# validation
rf_pred_d_valid <- predict(rf_d, newdata = ebay.valid, type = "prob")
rf_d_valid_con <- confusionMatrix(factor(rf_pred_d_valid[,2]>cutoff, labels = c(0,1)), ebay.valid$competitive.factor)$overall['Accuracy']
rf_d_valid_con
hclust_sil <- silhouette(assignments,distances)
hclust_silAgg <- aggregate(hclust_sil, list(hclust_sil[,"cluster"]), FUN=mean)
hclust_silAgg
hclust_silOverall <- mean(hclust_sil[,3])
hclust_silOverall
plot(cluster.assignment.kmeans, col=1:8, border=NA)
plot(assignments, col=1:8, border=NA)
table(assignments, cluster.assignment.kmeans)
library(cluster)
distances <- dist(returns)
kmeans_sil <- silhouette(cluster.assignment.kmeans,distances)
kmeans_silAgg <- aggregate(kmeans_sil, list(kmeans_sil[,"cluster"]), FUN=mean)
kmeans_silAgg
kmeans_silOverall <- mean(kmeans_sil[,3])
kmeans_silOverall
hclust_sil <- silhouette(assignments,distances)
hclust_silAgg <- aggregate(hclust_sil, list(hclust_sil[,"cluster"]), FUN=mean)
hclust_silAgg
hclust_silOverall <- mean(hclust_sil[,3])
hclust_silOverall
plot(cluster.assignment.kmeans, col=1:8, border=NA)
plot(assignments, col=1:8, border=NA)
#p <- ggplot(averages_t, aes(x=`Group.1`[,23:58], y=`Consumer Discretionary`[,23:58])) +
#geom_line()
#p
# for (i in colnames(plot_avg_t)) {
#   plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t), y = plot_avg_t[,i], group = 1)) +
#     geom_line()+
#     labs(title = i, x = "Date", y = "Average Return") +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1))
#   print(plot)
#
# }
#colors <- c("Sepal Width" = "blue", "Petal Length" = "red", "Petal Width" = "orange")
plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t))) +
geom_line(aes(y = plot_avg_t[,1], group = 1), color="red") +
geom_line(aes(y = plot_avg_t[,2], group = 1), color="orange") +
geom_line(aes(y = plot_avg_t[,3], group = 1), color="gold") +
geom_line(aes(y = plot_avg_t[,4], group = 1), color="darkgreen") +
geom_line(aes(y = plot_avg_t[,5], group = 1), color="green") +
geom_line(aes(y = plot_avg_t[,6], group = 1), color="darkblue") +
geom_line(aes(y = plot_avg_t[,7], group = 1), color="blue") +
geom_line(aes(y = plot_avg_t[,8], group = 1), color="purple") +
geom_line(aes(y = plot_avg_t[,9], group = 1), color="brown") +
geom_line(aes(y = plot_avg_t[,10], group = 1), color="pink") +
geom_line(aes(y=0), color="black") +
labs(title = "Returns by Industry", x = "Date", y = "Average Return", color = "Legend") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
print(plot)
#p <- ggplot(averages_t, aes(x=`Group.1`[,23:58], y=`Consumer Discretionary`[,23:58])) +
#geom_line()
#p
# for (i in colnames(plot_avg_t)) {
#   plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t), y = plot_avg_t[,i], group = 1)) +
#     geom_line()+
#     labs(title = i, x = "Date", y = "Average Return") +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1))
#   print(plot)
#
# }
#colors <- c("Sepal Width" = "blue", "Petal Length" = "red", "Petal Width" = "orange")
plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t))) +
geom_line(aes(y = plot_avg_t[,1], group = 1), color="red") +
geom_line(aes(y = plot_avg_t[,2], group = 1), color="orange") +
geom_line(aes(y = plot_avg_t[,3], group = 1), color="gold") +
geom_line(aes(y = plot_avg_t[,4], group = 1), color="darkgreen") +
geom_line(aes(y = plot_avg_t[,5], group = 1), color="green") +
geom_line(aes(y = plot_avg_t[,6], group = 1), color="darkblue") +
geom_line(aes(y = plot_avg_t[,7], group = 1), color="blue") +
geom_line(aes(y = plot_avg_t[,8], group = 1), color="purple") +
geom_line(aes(y = plot_avg_t[,9], group = 1), color="brown") +
geom_line(aes(y = plot_avg_t[,10], group = 1), color="pink") +
geom_hline(yintercept=0, color="black") +
labs(title = "Returns by Industry", x = "Date", y = "Average Return", color = "Legend") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
print(plot)
#p <- ggplot(averages_t, aes(x=`Group.1`[,23:58], y=`Consumer Discretionary`[,23:58])) +
#geom_line()
#p
# for (i in colnames(plot_avg_t)) {
#   plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t), y = plot_avg_t[,i], group = 1)) +
#     geom_line()+
#     labs(title = i, x = "Date", y = "Average Return") +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1))
#   print(plot)
#
# }
#colors <- c("Sepal Width" = "blue", "Petal Length" = "red", "Petal Width" = "orange")
plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t))) +
geom_line(aes(y = plot_avg_t[,1], group = 1), color="red") +
geom_line(aes(y = plot_avg_t[,2], group = 1), color="orange") +
geom_line(aes(y = plot_avg_t[,3], group = 1), color="gold") +
geom_line(aes(y = plot_avg_t[,4], group = 1), color="darkgreen") +
geom_line(aes(y = plot_avg_t[,5], group = 1), color="green") +
geom_line(aes(y = plot_avg_t[,6], group = 1), color="darkblue") +
geom_line(aes(y = plot_avg_t[,7], group = 1), color="blue") +
geom_line(aes(y = plot_avg_t[,8], group = 1), color="purple") +
geom_line(aes(y = plot_avg_t[,9], group = 1), color="brown") +
geom_line(aes(y = plot_avg_t[,10], group = 1), color="pink") +
geom_hline(aes(yintercept=0), color="black") +
labs(title = "Returns by Industry", x = "Date", y = "Average Return", color = "Legend") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
print(plot)
#p <- ggplot(averages_t, aes(x=`Group.1`[,23:58], y=`Consumer Discretionary`[,23:58])) +
#geom_line()
#p
# for (i in colnames(plot_avg_t)) {
#   plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t), y = plot_avg_t[,i], group = 1)) +
#     geom_line()+
#     labs(title = i, x = "Date", y = "Average Return") +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1))
#   print(plot)
#
# }
#colors <- c("Sepal Width" = "blue", "Petal Length" = "red", "Petal Width" = "orange")
plot = ggplot(data = plot_avg_t, aes(x = rownames(plot_avg_t))) +
geom_line(aes(y = plot_avg_t[,1], group = 1), color="red") +
geom_line(aes(y = plot_avg_t[,2], group = 1), color="orange") +
geom_line(aes(y = plot_avg_t[,3], group = 1), color="gold") +
geom_line(aes(y = plot_avg_t[,4], group = 1), color="darkgreen") +
geom_line(aes(y = plot_avg_t[,5], group = 1), color="green") +
geom_line(aes(y = plot_avg_t[,6], group = 1), color="darkblue") +
geom_line(aes(y = plot_avg_t[,7], group = 1), color="blue") +
geom_line(aes(y = plot_avg_t[,8], group = 1), color="purple") +
geom_line(aes(y = plot_avg_t[,9], group = 1), color="brown") +
geom_line(aes(y = plot_avg_t[,10], group = 1), color="pink") +
geom_hline(aes(yintercept=0, color="black")) +
labs(title = "Returns by Industry", x = "Date", y = "Average Return", color = "Legend") +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
print(plot)
sum(ebay.valid$Competitive.==1)/nrow(ebay.valid)
